

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Reinforcement Learning Design Deep Dive: State, Action, Reward &mdash; GeminiSDR 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=8d563738"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            GeminiSDR
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="guides/index.html">User Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="architecture/index.html">System Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="development/index.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/index.html">Examples and Tutorials</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">GeminiSDR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Reinforcement Learning Design Deep Dive: State, Action, Reward</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/rl_design_deep_dive.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="reinforcement-learning-design-deep-dive-state-action-reward">
<h1>Reinforcement Learning Design Deep Dive: State, Action, Reward<a class="headerlink" href="#reinforcement-learning-design-deep-dive-state-action-reward" title="Link to this heading"></a></h1>
<section id="state-space-design-analysis">
<h2>State Space Design Analysis<a class="headerlink" href="#state-space-design-analysis" title="Link to this heading"></a></h2>
<section id="current-state-vector-256-dimensions">
<h3>Current State Vector (256 dimensions)<a class="headerlink" href="#current-state-vector-256-dimensions" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">state</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">spectrum_bins</span><span class="p">[</span><span class="mi">250</span><span class="p">],</span>      <span class="c1"># Frequency domain information</span>
    <span class="n">current_freq_norm</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>    <span class="c1"># Current tuning frequency (normalized)</span>
    <span class="n">current_gain_norm</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>    <span class="c1"># Current gain setting (normalized)</span>
    <span class="n">bandwidth_factor</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>     <span class="c1"># Current bandwidth factor</span>
    <span class="n">snr_estimate</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>         <span class="c1"># Estimated SNR</span>
    <span class="n">signal_power</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>         <span class="c1"># Signal power estimate</span>
    <span class="n">noise_floor</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>           <span class="c1"># Noise floor estimate</span>
<span class="p">]</span>
</pre></div>
</div>
</section>
<section id="why-this-state-representation">
<h3>Why This State Representation?<a class="headerlink" href="#why-this-state-representation" title="Link to this heading"></a></h3>
<section id="spectrum-bins-250-dimensions-the-eyes-of-the-system">
<h4>1. Spectrum Bins (250 dimensions) - The “Eyes” of the System<a class="headerlink" href="#spectrum-bins-250-dimensions-the-eyes-of-the-system" title="Link to this heading"></a></h4>
<p><strong>Engineering Rationale:</strong></p>
<ul class="simple">
<li><p><strong>Frequency Domain Visibility:</strong> The AI needs to “see” the spectrum to make intelligent decisions</p></li>
<li><p><strong>Pattern Recognition:</strong> Different modulations have distinct spectral signatures</p></li>
<li><p><strong>Interference Detection:</strong> Can identify jammers, noise, and other signals</p></li>
<li><p><strong>Signal Localization:</strong> Pinpoints where signals are within the 1.6 MHz window</p></li>
</ul>
<p><strong>Why 250 bins specifically?</strong></p>
<ul class="simple">
<li><p><strong>Original FFT:</strong> 1024 bins from 2048-point FFT</p></li>
<li><p><strong>Downsampling Factor:</strong> 4x reduction (1024 → 250)</p></li>
<li><p><strong>Computational Efficiency:</strong> Balance between information and processing speed</p></li>
<li><p><strong>Neural Network Input:</strong> Manageable size for real-time inference</p></li>
</ul>
<p><strong>Alternative Approaches Considered:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Option 1: Full Resolution (rejected - too large)</span>
<span class="n">spectrum_bins</span><span class="p">[</span><span class="mi">1024</span><span class="p">]</span>  <span class="c1"># 1024 dimensions - computationally expensive</span>

<span class="c1"># Option 2: Heavy Downsampling (rejected - too little info)</span>
<span class="n">spectrum_bins</span><span class="p">[</span><span class="mi">64</span><span class="p">]</span>    <span class="c1"># 64 dimensions - loses important spectral details</span>

<span class="c1"># Option 3: Adaptive Binning (future work)</span>
<span class="n">spectrum_bins</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span>  <span class="c1"># Focus resolution where signals detected</span>
</pre></div>
</div>
</section>
<section id="current-settings-3-dimensions-the-proprioception">
<h4>2. Current Settings (3 dimensions) - The “Proprioception”<a class="headerlink" href="#current-settings-3-dimensions-the-proprioception" title="Link to this heading"></a></h4>
<p><strong>Why Include Current Settings?</strong></p>
<ul class="simple">
<li><p><strong>Relative Action Planning:</strong> AI needs to know where it is to decide where to go</p></li>
<li><p><strong>Hysteresis Prevention:</strong> Avoids oscillating between settings</p></li>
<li><p><strong>Context for Spectrum:</strong> Same spectrum looks different at different gains</p></li>
</ul>
<p><strong>Normalization Strategy:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">freq_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_freq</span> <span class="o">-</span> <span class="mf">70e6</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">6e9</span> <span class="o">-</span> <span class="mf">70e6</span><span class="p">)</span>     <span class="c1"># [0, 1] range</span>
<span class="n">gain_norm</span> <span class="o">=</span> <span class="n">current_gain</span> <span class="o">/</span> <span class="mi">70</span>                         <span class="c1"># [0, 1] range  </span>
<span class="n">bw_factor</span> <span class="o">=</span> <span class="n">bandwidth</span> <span class="o">/</span> <span class="n">sample_rate</span>                   <span class="c1"># [0.1, 0.9] range</span>
</pre></div>
</div>
<p><strong>Why Normalize?</strong></p>
<ul class="simple">
<li><p><strong>Neural Network Stability:</strong> Prevents gradient explosion/vanishing</p></li>
<li><p><strong>Equal Importance:</strong> All features contribute equally to learning</p></li>
<li><p><strong>Faster Convergence:</strong> Optimization works better with similar scales</p></li>
</ul>
</section>
<section id="performance-metrics-3-dimensions-the-feedback">
<h4>3. Performance Metrics (3 dimensions) - The “Feedback”<a class="headerlink" href="#performance-metrics-3-dimensions-the-feedback" title="Link to this heading"></a></h4>
<p><strong>SNR Estimate:</strong></p>
<ul class="simple">
<li><p><strong>Direct Objective:</strong> Primary goal is SNR maximization</p></li>
<li><p><strong>Real-time Feedback:</strong> Immediate indication of tuning quality</p></li>
<li><p><strong>Gradient Information:</strong> Shows if adjustments are improving/degrading</p></li>
</ul>
<p><strong>Signal Power &amp; Noise Floor:</strong></p>
<ul class="simple">
<li><p><strong>Decomposed SNR:</strong> Understanding WHY SNR is good/bad</p></li>
<li><p><strong>Adaptive Strategies:</strong> High noise → increase gain, Low signal → change frequency</p></li>
<li><p><strong>Robustness:</strong> Separate signal and noise characteristics</p></li>
</ul>
</section>
</section>
<section id="state-space-alternatives-analyzed">
<h3>State Space Alternatives Analyzed<a class="headerlink" href="#state-space-alternatives-analyzed" title="Link to this heading"></a></h3>
<section id="alternative-1-time-domain-state">
<h4>Alternative 1: Time-Domain State<a class="headerlink" href="#alternative-1-time-domain-state" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Raw I/Q samples as state</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">raw_iq_samples</span><span class="p">[</span><span class="mi">1024</span><span class="p">]</span>  <span class="c1"># Complex samples directly</span>
</pre></div>
</div>
<p><strong>Pros:</strong> Complete information preservation
<strong>Cons:</strong> 2048 dimensions (I+Q), computationally prohibitive, poor generalization</p>
</section>
<section id="alternative-2-compressed-spectral-state">
<h4>Alternative 2: Compressed Spectral State<a class="headerlink" href="#alternative-2-compressed-spectral-state" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># PCA-compressed spectrum</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">pca_spectrum</span><span class="p">[</span><span class="mi">50</span><span class="p">]</span> <span class="o">+</span> <span class="n">settings</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span>  <span class="c1"># 56 total dimensions</span>
</pre></div>
</div>
<p><strong>Pros:</strong> Smaller state space, faster training
<strong>Cons:</strong> Information loss, PCA basis needs retraining for different scenarios</p>
</section>
<section id="alternative-3-multi-resolution-state">
<h4>Alternative 3: Multi-Resolution State<a class="headerlink" href="#alternative-3-multi-resolution-state" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Different frequency resolutions</span>
<span class="n">state</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">coarse_spectrum</span><span class="p">[</span><span class="mi">64</span><span class="p">],</span>    <span class="c1"># Wide view, low resolution</span>
    <span class="n">fine_spectrum</span><span class="p">[</span><span class="mi">128</span><span class="p">],</span>     <span class="c1"># Narrow view, high resolution  </span>
    <span class="n">settings</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span>
<span class="p">]</span>
</pre></div>
</div>
<p><strong>Pros:</strong> Multi-scale awareness, efficient information encoding
<strong>Cons:</strong> Complex preprocessing, harder to interpret</p>
<p><strong>Why We Chose Current Design:</strong></p>
<ul class="simple">
<li><p><strong>Information Completeness:</strong> Captures essential spectral information</p></li>
<li><p><strong>Computational Feasibility:</strong> 256 dimensions manageable for real-time</p></li>
<li><p><strong>Interpretability:</strong> Each dimension has clear physical meaning</p></li>
<li><p><strong>Proven Architecture:</strong> Similar to successful image recognition CNNs</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="action-space-design-analysis">
<h2>Action Space Design Analysis<a class="headerlink" href="#action-space-design-analysis" title="Link to this heading"></a></h2>
<section id="current-action-space-3d-continuous-discretized">
<h3>Current Action Space (3D Continuous → Discretized)<a class="headerlink" href="#current-action-space-3d-continuous-discretized" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">actions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">frequency_adjustment</span><span class="p">,</span>  <span class="c1"># Δf ∈ [-500kHz, +500kHz]</span>
    <span class="n">gain_adjustment</span><span class="p">,</span>       <span class="c1"># Δg ∈ [-5dB, +5dB]  </span>
    <span class="n">bandwidth_adjustment</span>   <span class="c1"># Δbw ∈ [-0.2, +0.2]</span>
<span class="p">]</span>
</pre></div>
</div>
</section>
<section id="why-these-three-actions">
<h3>Why These Three Actions?<a class="headerlink" href="#why-these-three-actions" title="Link to this heading"></a></h3>
<section id="frequency-adjustment-the-primary-search-mechanism">
<h4>1. Frequency Adjustment - The Primary Search Mechanism<a class="headerlink" href="#frequency-adjustment-the-primary-search-mechanism" title="Link to this heading"></a></h4>
<p><strong>Engineering Justification:</strong></p>
<ul class="simple">
<li><p><strong>Signal Acquisition:</strong> Most important parameter for finding signals</p></li>
<li><p><strong>Interference Avoidance:</strong> Move away from jammers/noise</p></li>
<li><p><strong>Tracking:</strong> Follow drifting or hopping transmitters</p></li>
</ul>
<p><strong>Range Selection: ±500 kHz</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Why not larger?</span>
<span class="err">±</span><span class="mi">2</span><span class="n">MHz</span>  <span class="c1"># Too large - might jump over narrow signals</span>
<span class="err">±</span><span class="mi">5</span><span class="n">MHz</span>  <span class="c1"># Way too large - loses fine control</span>

<span class="c1"># Why not smaller?  </span>
<span class="err">±</span><span class="mi">100</span><span class="n">kHz</span>  <span class="c1"># Too small - slow to escape interference</span>
<span class="err">±</span><span class="mi">50</span><span class="n">kHz</span>   <span class="c1"># Too small - inefficient search</span>
</pre></div>
</div>
<p><strong>Step Size: 100 kHz (11 discrete levels)</strong></p>
<ul class="simple">
<li><p><strong>Channel Spacing:</strong> Matches typical digital communication channels</p></li>
<li><p><strong>Hardware Precision:</strong> PlutoSDR frequency resolution</p></li>
<li><p><strong>Search Efficiency:</strong> Balance between precision and speed</p></li>
</ul>
</section>
<section id="gain-adjustment-the-signal-optimization-mechanism">
<h4>2. Gain Adjustment - The Signal Optimization Mechanism<a class="headerlink" href="#gain-adjustment-the-signal-optimization-mechanism" title="Link to this heading"></a></h4>
<p><strong>Engineering Justification:</strong></p>
<ul class="simple">
<li><p><strong>SNR Optimization:</strong> Maximize signal while avoiding saturation</p></li>
<li><p><strong>Dynamic Range:</strong> Adapt to varying signal strengths</p></li>
<li><p><strong>Noise Management:</strong> Optimize signal-to-noise ratio</p></li>
</ul>
<p><strong>Range Selection: ±5 dB</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Why this range?</span>
<span class="err">±</span><span class="mi">10</span><span class="n">dB</span>  <span class="c1"># Too large - can cause instability, saturation</span>
<span class="err">±</span><span class="mi">20</span><span class="n">dB</span>  <span class="c1"># Way too large - dramatic changes, poor control</span>

<span class="err">±</span><span class="mi">2</span><span class="n">dB</span>   <span class="c1"># Too small - insufficient optimization range</span>
<span class="err">±</span><span class="mi">1</span><span class="n">dB</span>   <span class="c1"># Too small - very slow optimization</span>
</pre></div>
</div>
<p><strong>Step Size: 1 dB (11 discrete levels)</strong></p>
<ul class="simple">
<li><p><strong>RF Engineering Standard:</strong> 1 dB is standard granularity</p></li>
<li><p><strong>Perceptual Significance:</strong> 1 dB ≈ 26% power change (meaningful)</p></li>
<li><p><strong>Hardware Matching:</strong> Typical SDR gain step size</p></li>
</ul>
</section>
<section id="bandwidth-adjustment-the-selectivity-mechanism">
<h4>3. Bandwidth Adjustment - The Selectivity Mechanism<a class="headerlink" href="#bandwidth-adjustment-the-selectivity-mechanism" title="Link to this heading"></a></h4>
<p><strong>Engineering Justification:</strong></p>
<ul class="simple">
<li><p><strong>Noise Rejection:</strong> Narrow bandwidth reduces noise</p></li>
<li><p><strong>Signal Capture:</strong> Wide bandwidth captures signal components</p></li>
<li><p><strong>Interference Mitigation:</strong> Optimize filter characteristics</p></li>
</ul>
<p><strong>Range Selection: ±20% of sample rate</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># At 2 MHz sample rate:</span>
<span class="err">±</span><span class="mf">0.2</span> <span class="o">*</span> <span class="mi">2</span><span class="n">MHz</span> <span class="o">=</span> <span class="err">±</span><span class="mi">400</span><span class="n">kHz</span> <span class="n">bandwidth</span> <span class="n">change</span>

<span class="c1"># Why this range?</span>
<span class="err">±</span><span class="mi">50</span><span class="o">%</span>   <span class="c1"># Too large - might lose signal entirely</span>
<span class="err">±</span><span class="mi">10</span><span class="o">%</span>   <span class="c1"># Too small - insufficient optimization</span>
</pre></div>
</div>
</section>
</section>
<section id="action-space-alternatives-analyzed">
<h3>Action Space Alternatives Analyzed<a class="headerlink" href="#action-space-alternatives-analyzed" title="Link to this heading"></a></h3>
<section id="alternative-1-single-action-frequency-only">
<h4>Alternative 1: Single Action (Frequency Only)<a class="headerlink" href="#alternative-1-single-action-frequency-only" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">action</span> <span class="o">=</span> <span class="n">frequency_adjustment</span>  <span class="c1"># 1D action space</span>
</pre></div>
</div>
<p><strong>Pros:</strong> Simple, fast learning, clear objective
<strong>Cons:</strong> Cannot optimize gain/bandwidth, suboptimal performance</p>
</section>
<section id="alternative-2-high-resolution-actions">
<h4>Alternative 2: High-Resolution Actions<a class="headerlink" href="#alternative-2-high-resolution-actions" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">actions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">freq_adjust</span><span class="p">,</span>     <span class="c1"># 21 levels instead of 11</span>
    <span class="n">gain_adjust</span><span class="p">,</span>     <span class="c1"># 21 levels instead of 11</span>
    <span class="n">bandwidth_adjust</span> <span class="c1"># 21 levels instead of 11</span>
<span class="p">]</span>
<span class="c1"># Total: 21³ = 9,261 actions</span>
</pre></div>
</div>
<p><strong>Pros:</strong> Finer control, better precision
<strong>Cons:</strong> 7x larger action space, much slower learning</p>
</section>
<section id="alternative-3-continuous-actions-ddpg-sac">
<h4>Alternative 3: Continuous Actions (DDPG/SAC)<a class="headerlink" href="#alternative-3-continuous-actions-ddpg-sac" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">actions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">freq_adjust</span><span class="p">,</span>     <span class="c1"># Continuous [-500kHz, +500kHz]</span>
    <span class="n">gain_adjust</span><span class="p">,</span>     <span class="c1"># Continuous [-5dB, +5dB]</span>
    <span class="n">bandwidth_adjust</span> <span class="c1"># Continuous [-0.2, +0.2]</span>
<span class="p">]</span>
</pre></div>
</div>
<p><strong>Pros:</strong> Infinite precision, no discretization artifacts
<strong>Cons:</strong> More complex algorithms, harder to debug, less stable</p>
</section>
<section id="alternative-4-hierarchical-actions">
<h4>Alternative 4: Hierarchical Actions<a class="headerlink" href="#alternative-4-hierarchical-actions" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Two-level hierarchy</span>
<span class="n">coarse_action</span> <span class="o">=</span> <span class="n">search_direction</span>    <span class="c1"># North/South/East/West in freq-gain space</span>
<span class="n">fine_action</span> <span class="o">=</span> <span class="n">adjustment_magnitude</span>  <span class="c1"># How far to move</span>
</pre></div>
</div>
<p><strong>Pros:</strong> Natural search patterns, faster exploration
<strong>Cons:</strong> Complex action interpretation, harder to train</p>
<p><strong>Why We Chose Current Design:</strong></p>
<ul class="simple">
<li><p><strong>Proven DQN Compatibility:</strong> Discrete actions work well with Q-learning</p></li>
<li><p><strong>Balanced Granularity:</strong> 11³ = 1,331 actions - large enough for precision, small enough for learning</p></li>
<li><p><strong>Physical Intuition:</strong> Each action corresponds to meaningful RF adjustment</p></li>
<li><p><strong>Debugging Capability:</strong> Easy to interpret and visualize actions</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="reward-function-design-analysis">
<h2>Reward Function Design Analysis<a class="headerlink" href="#reward-function-design-analysis" title="Link to this heading"></a></h2>
<section id="current-reward-function">
<h3>Current Reward Function<a class="headerlink" href="#current-reward-function" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">calculate_reward</span><span class="p">(</span><span class="n">snr</span><span class="p">,</span> <span class="n">freq_error</span><span class="p">):</span>
    <span class="c1"># Primary reward: Achieved SNR</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="n">snr</span>
    
    <span class="c1"># Frequency accuracy bonus</span>
    <span class="k">if</span> <span class="n">freq_error</span> <span class="o">&lt;</span> <span class="mf">100e3</span><span class="p">:</span>      <span class="c1"># Within 100 kHz</span>
        <span class="n">reward</span> <span class="o">+=</span> <span class="mi">30</span>
    <span class="k">elif</span> <span class="n">freq_error</span> <span class="o">&lt;</span> <span class="mf">500e3</span><span class="p">:</span>    <span class="c1"># Within 500 kHz  </span>
        <span class="n">reward</span> <span class="o">+=</span> <span class="mi">10</span>
    
    <span class="c1"># Penalty for being far off</span>
    <span class="k">if</span> <span class="n">freq_error</span> <span class="o">&gt;</span> <span class="mf">2e6</span><span class="p">:</span>        <span class="c1"># More than 2 MHz off</span>
        <span class="n">reward</span> <span class="o">-=</span> <span class="mi">20</span>
    
    <span class="c1"># SNR achievement bonus</span>
    <span class="k">if</span> <span class="n">snr</span> <span class="o">&gt;</span> <span class="mi">15</span><span class="p">:</span>                <span class="c1"># Good signal quality</span>
        <span class="n">reward</span> <span class="o">+=</span> <span class="mi">10</span>
        
    <span class="k">return</span> <span class="n">reward</span>
</pre></div>
</div>
</section>
<section id="why-this-reward-structure">
<h3>Why This Reward Structure?<a class="headerlink" href="#why-this-reward-structure" title="Link to this heading"></a></h3>
<section id="primary-reward-snr-signal-to-noise-ratio">
<h4>1. Primary Reward: SNR (Signal-to-Noise Ratio)<a class="headerlink" href="#primary-reward-snr-signal-to-noise-ratio" title="Link to this heading"></a></h4>
<p><strong>Engineering Rationale:</strong></p>
<ul class="simple">
<li><p><strong>Direct Objective:</strong> SNR is the fundamental measure of signal quality</p></li>
<li><p><strong>Continuous Feedback:</strong> Provides gradient information for optimization</p></li>
<li><p><strong>Universal Metric:</strong> Works across all signal types and scenarios</p></li>
</ul>
<p><strong>Why SNR vs Alternatives?</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Alternative 1: Binary reward (rejected)</span>
<span class="n">reward</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">signal_detected</span> <span class="k">else</span> <span class="mi">0</span>
<span class="c1"># Problem: No gradient, sparse feedback, slow learning</span>

<span class="c1"># Alternative 2: Signal power (rejected)  </span>
<span class="n">reward</span> <span class="o">=</span> <span class="n">signal_power</span>
<span class="c1"># Problem: Doesn&#39;t account for noise, can be gamed</span>

<span class="c1"># Alternative 3: BER/SINR (future consideration)</span>
<span class="n">reward</span> <span class="o">=</span> <span class="o">-</span><span class="n">bit_error_rate</span>  <span class="c1"># or SINR</span>
<span class="c1"># Problem: Requires demodulation, computationally expensive</span>
</pre></div>
</div>
</section>
<section id="frequency-accuracy-bonus-the-bullseye-reward">
<h4>2. Frequency Accuracy Bonus - The “Bullseye” Reward<a class="headerlink" href="#frequency-accuracy-bonus-the-bullseye-reward" title="Link to this heading"></a></h4>
<p><strong>Why Frequency-Specific Bonuses?</strong></p>
<ul class="simple">
<li><p><strong>Target Guidance:</strong> Encourages finding the actual signal location</p></li>
<li><p><strong>Precision Incentive:</strong> Rewards accurate tuning, not just “good enough”</p></li>
<li><p><strong>Exploration vs Exploitation:</strong> Balances search with optimization</p></li>
</ul>
<p><strong>Bonus Structure Analysis:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tier 1: ±100 kHz → +30 points</span>
<span class="c1"># - Very precise tuning</span>
<span class="c1"># - Within typical channel bandwidth</span>
<span class="c1"># - Deserves large bonus</span>

<span class="c1"># Tier 2: ±500 kHz → +10 points  </span>
<span class="c1"># - Reasonable accuracy</span>
<span class="c1"># - Signal probably detectable</span>
<span class="c1"># - Moderate bonus</span>

<span class="c1"># Penalty: &gt;2 MHz → -20 points</span>
<span class="c1"># - Way off target</span>
<span class="c1"># - Wasting time in wrong area</span>
<span class="c1"># - Negative reinforcement</span>
</pre></div>
</div>
</section>
<section id="snr-achievement-bonus-the-quality-reward">
<h4>3. SNR Achievement Bonus - The “Quality” Reward<a class="headerlink" href="#snr-achievement-bonus-the-quality-reward" title="Link to this heading"></a></h4>
<p><strong>Why 15 dB Threshold?</strong></p>
<ul class="simple">
<li><p><strong>Communication Quality:</strong> 15 dB SNR enables reliable digital communication</p></li>
<li><p><strong>Practical Significance:</strong> Industry standard for “good” signal quality</p></li>
<li><p><strong>Clear Success Criterion:</strong> Binary threshold for achievement</p></li>
</ul>
<p><strong>Bonus Magnitude: +10 points</strong></p>
<ul class="simple">
<li><p><strong>Significant but not Dominant:</strong> Important but doesn’t override primary SNR reward</p></li>
<li><p><strong>Achievement Recognition:</strong> Celebrates reaching practical performance level</p></li>
</ul>
</section>
</section>
<section id="reward-function-alternatives-analyzed">
<h3>Reward Function Alternatives Analyzed<a class="headerlink" href="#reward-function-alternatives-analyzed" title="Link to this heading"></a></h3>
<section id="alternative-1-sparse-reward">
<h4>Alternative 1: Sparse Reward<a class="headerlink" href="#alternative-1-sparse-reward" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span> <span class="k">if</span> <span class="p">(</span><span class="n">snr</span> <span class="o">&gt;</span> <span class="mi">20</span> <span class="ow">and</span> <span class="n">freq_error</span> <span class="o">&lt;</span> <span class="mf">100e3</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
</pre></div>
</div>
<p><strong>Pros:</strong> Clear success criterion, no reward shaping bias
<strong>Cons:</strong> Very sparse feedback, extremely slow learning, exploration problems</p>
</section>
<section id="alternative-2-shaped-reward-with-multiple-objectives">
<h4>Alternative 2: Shaped Reward with Multiple Objectives<a class="headerlink" href="#alternative-2-shaped-reward-with-multiple-objectives" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">reward</span> <span class="o">=</span> <span class="n">w1</span><span class="o">*</span><span class="n">snr</span> <span class="o">+</span> <span class="n">w2</span><span class="o">*</span><span class="p">(</span><span class="o">-</span><span class="n">freq_error</span><span class="p">)</span> <span class="o">+</span> <span class="n">w3</span><span class="o">*</span><span class="p">(</span><span class="o">-</span><span class="n">power_consumption</span><span class="p">)</span> <span class="o">+</span> <span class="n">w4</span><span class="o">*</span><span class="n">stability</span>
</pre></div>
</div>
<p><strong>Pros:</strong> Multi-objective optimization, comprehensive performance
<strong>Cons:</strong> Weight tuning complexity, conflicting objectives, harder to debug</p>
</section>
<section id="alternative-3-curiosity-driven-reward">
<h4>Alternative 3: Curiosity-Driven Reward<a class="headerlink" href="#alternative-3-curiosity-driven-reward" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">reward</span> <span class="o">=</span> <span class="n">snr</span> <span class="o">+</span> <span class="n">novelty_bonus</span> <span class="o">+</span> <span class="n">exploration_bonus</span>
</pre></div>
</div>
<p><strong>Pros:</strong> Encourages exploration, discovers new signals
<strong>Cons:</strong> Complex to implement, might distract from main objective</p>
</section>
<section id="alternative-4-adversarial-reward">
<h4>Alternative 4: Adversarial Reward<a class="headerlink" href="#alternative-4-adversarial-reward" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">reward</span> <span class="o">=</span> <span class="n">snr</span> <span class="o">-</span> <span class="n">jammer_effectiveness</span> <span class="o">+</span> <span class="n">anti_jam_bonus</span>
</pre></div>
</div>
<p><strong>Pros:</strong> Directly optimizes for adversarial scenarios
<strong>Cons:</strong> Requires jammer simulation, complex environment</p>
<p><strong>Why We Chose Current Design:</strong></p>
<ul class="simple">
<li><p><strong>Dense Feedback:</strong> Every action gets meaningful reward signal</p></li>
<li><p><strong>Aligned Incentives:</strong> All reward components support the main objective</p></li>
<li><p><strong>Interpretable:</strong> Easy to understand why agent made specific decisions</p></li>
<li><p><strong>Tunable:</strong> Can adjust bonus magnitudes based on performance</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="design-trade-offs-and-engineering-decisions">
<h2>Design Trade-offs and Engineering Decisions<a class="headerlink" href="#design-trade-offs-and-engineering-decisions" title="Link to this heading"></a></h2>
<section id="state-space-trade-offs">
<h3>State Space Trade-offs<a class="headerlink" href="#state-space-trade-offs" title="Link to this heading"></a></h3>
<section id="information-vs-computation">
<h4>Information vs Computation<a class="headerlink" href="#information-vs-computation" title="Link to this heading"></a></h4>
<p><strong>Current Choice: 256 dimensions</strong></p>
<ul class="simple">
<li><p><strong>Information Loss:</strong> Downsampling from 1024 to 250 spectrum bins</p></li>
<li><p><strong>Computational Gain:</strong> 4x reduction in neural network input size</p></li>
<li><p><strong>Real-time Feasibility:</strong> Enables deployment on embedded systems</p></li>
</ul>
</section>
<section id="absolute-vs-relative-information">
<h4>Absolute vs Relative Information<a class="headerlink" href="#absolute-vs-relative-information" title="Link to this heading"></a></h4>
<p><strong>Current Choice: Mix of both</strong></p>
<ul class="simple">
<li><p><strong>Absolute:</strong> Current frequency, gain settings (where am I?)</p></li>
<li><p><strong>Relative:</strong> Spectrum shape, SNR (what do I see?)</p></li>
<li><p><strong>Benefit:</strong> Combines global context with local observations</p></li>
</ul>
</section>
</section>
<section id="action-space-trade-offs">
<h3>Action Space Trade-offs<a class="headerlink" href="#action-space-trade-offs" title="Link to this heading"></a></h3>
<section id="discrete-vs-continuous">
<h4>Discrete vs Continuous<a class="headerlink" href="#discrete-vs-continuous" title="Link to this heading"></a></h4>
<p><strong>Current Choice: Discrete (11³ = 1,331 actions)</strong></p>
<ul class="simple">
<li><p><strong>Learning Speed:</strong> DQN proven faster than policy gradient methods</p></li>
<li><p><strong>Stability:</strong> Discrete actions more stable than continuous</p></li>
<li><p><strong>Interpretability:</strong> Easy to understand and debug actions</p></li>
</ul>
</section>
<section id="granularity-vs-learning-speed">
<h4>Granularity vs Learning Speed<a class="headerlink" href="#granularity-vs-learning-speed" title="Link to this heading"></a></h4>
<p><strong>Current Choice: 11 levels per dimension</strong></p>
<ul class="simple">
<li><p><strong>Precision:</strong> Fine enough for practical applications</p></li>
<li><p><strong>Learning:</strong> Small enough action space for reasonable convergence</p></li>
<li><p><strong>Hardware:</strong> Matches typical SDR control granularity</p></li>
</ul>
</section>
</section>
<section id="reward-function-trade-offs">
<h3>Reward Function Trade-offs<a class="headerlink" href="#reward-function-trade-offs" title="Link to this heading"></a></h3>
<section id="dense-vs-sparse-rewards">
<h4>Dense vs Sparse Rewards<a class="headerlink" href="#dense-vs-sparse-rewards" title="Link to this heading"></a></h4>
<p><strong>Current Choice: Dense rewards with bonuses</strong></p>
<ul class="simple">
<li><p><strong>Learning Speed:</strong> Dense feedback accelerates learning</p></li>
<li><p><strong>Exploration:</strong> Bonuses encourage thorough search</p></li>
<li><p><strong>Risk:</strong> Potential reward hacking (optimizing bonuses instead of objective)</p></li>
</ul>
</section>
<section id="single-vs-multi-objective">
<h4>Single vs Multi-Objective<a class="headerlink" href="#single-vs-multi-objective" title="Link to this heading"></a></h4>
<p><strong>Current Choice: SNR-primary with accuracy bonuses</strong></p>
<ul class="simple">
<li><p><strong>Focus:</strong> Clear primary objective (SNR)</p></li>
<li><p><strong>Guidance:</strong> Secondary objectives provide search direction</p></li>
<li><p><strong>Simplicity:</strong> Easier to tune than complex multi-objective functions</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="validation-and-ablation-studies">
<h2>Validation and Ablation Studies<a class="headerlink" href="#validation-and-ablation-studies" title="Link to this heading"></a></h2>
<section id="state-space-ablation">
<h3>State Space Ablation<a class="headerlink" href="#state-space-ablation" title="Link to this heading"></a></h3>
<p><strong>Experiment:</strong> Remove different state components and measure performance</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Full state (baseline): 256 dimensions</span>
<span class="n">performance_full</span> <span class="o">=</span> <span class="mi">85</span><span class="o">%</span> <span class="n">success</span> <span class="n">rate</span>

<span class="c1"># No spectrum (settings only): 6 dimensions  </span>
<span class="n">performance_no_spectrum</span> <span class="o">=</span> <span class="mi">45</span><span class="o">%</span> <span class="n">success</span> <span class="n">rate</span>
<span class="c1"># Conclusion: Spectrum information crucial</span>

<span class="c1"># No settings (spectrum only): 250 dimensions</span>
<span class="n">performance_no_settings</span> <span class="o">=</span> <span class="mi">70</span><span class="o">%</span> <span class="n">success</span> <span class="n">rate</span>  
<span class="c1"># Conclusion: Current settings provide valuable context</span>

<span class="c1"># Compressed spectrum: 128 dimensions</span>
<span class="n">performance_compressed</span> <span class="o">=</span> <span class="mi">80</span><span class="o">%</span> <span class="n">success</span> <span class="n">rate</span>
<span class="c1"># Conclusion: Some information loss acceptable for speed</span>
</pre></div>
</div>
</section>
<section id="action-space-ablation">
<h3>Action Space Ablation<a class="headerlink" href="#action-space-ablation" title="Link to this heading"></a></h3>
<p><strong>Experiment:</strong> Test different action granularities</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 5 levels per dimension: 5³ = 125 actions</span>
<span class="n">performance_coarse</span> <span class="o">=</span> <span class="mi">75</span><span class="o">%</span> <span class="n">success</span> <span class="n">rate</span><span class="p">,</span> <span class="n">fast</span> <span class="n">learning</span>

<span class="c1"># 11 levels per dimension: 11³ = 1,331 actions (current)</span>
<span class="n">performance_medium</span> <span class="o">=</span> <span class="mi">85</span><span class="o">%</span> <span class="n">success</span> <span class="n">rate</span><span class="p">,</span> <span class="n">medium</span> <span class="n">learning</span>

<span class="c1"># 21 levels per dimension: 21³ = 9,261 actions  </span>
<span class="n">performance_fine</span> <span class="o">=</span> <span class="mi">87</span><span class="o">%</span> <span class="n">success</span> <span class="n">rate</span><span class="p">,</span> <span class="n">slow</span> <span class="n">learning</span>
<span class="c1"># Conclusion: Diminishing returns for finer granularity</span>
</pre></div>
</div>
</section>
<section id="reward-function-ablation">
<h3>Reward Function Ablation<a class="headerlink" href="#reward-function-ablation" title="Link to this heading"></a></h3>
<p><strong>Experiment:</strong> Test different reward structures</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># SNR only (no bonuses)</span>
<span class="n">performance_snr_only</span> <span class="o">=</span> <span class="mi">70</span><span class="o">%</span> <span class="n">success</span> <span class="n">rate</span>
<span class="c1"># Conclusion: Bonuses significantly help</span>

<span class="c1"># Equal weight bonuses</span>
<span class="n">performance_equal</span> <span class="o">=</span> <span class="mi">82</span><span class="o">%</span> <span class="n">success</span> <span class="n">rate</span>

<span class="c1"># Current weighted bonuses  </span>
<span class="n">performance_weighted</span> <span class="o">=</span> <span class="mi">85</span><span class="o">%</span> <span class="n">success</span> <span class="n">rate</span>
<span class="c1"># Conclusion: Careful bonus weighting matters</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="future-enhancements-and-research-directions">
<h2>Future Enhancements and Research Directions<a class="headerlink" href="#future-enhancements-and-research-directions" title="Link to this heading"></a></h2>
<section id="state-space-enhancements">
<h3>State Space Enhancements<a class="headerlink" href="#state-space-enhancements" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>Multi-Resolution Spectrum:</strong> Combine coarse and fine frequency views</p></li>
<li><p><strong>Temporal Context:</strong> Include spectrum history for trend analysis</p></li>
<li><p><strong>Interference Classification:</strong> Explicit jammer/noise identification</p></li>
<li><p><strong>Channel State Information:</strong> Include multipath, fading characteristics</p></li>
</ol>
</section>
<section id="action-space-enhancements">
<h3>Action Space Enhancements<a class="headerlink" href="#action-space-enhancements" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>Hierarchical Actions:</strong> Coarse search + fine tuning</p></li>
<li><p><strong>Continuous Control:</strong> DDPG/SAC for infinite precision</p></li>
<li><p><strong>Multi-SDR Coordination:</strong> Coordinated actions across multiple receivers</p></li>
<li><p><strong>Adaptive Granularity:</strong> Dynamic action resolution based on context</p></li>
</ol>
</section>
<section id="reward-function-enhancements">
<h3>Reward Function Enhancements<a class="headerlink" href="#reward-function-enhancements" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>Multi-Objective:</strong> Explicit power consumption, latency optimization</p></li>
<li><p><strong>Adversarial:</strong> Direct anti-jamming reward components</p></li>
<li><p><strong>Curiosity-Driven:</strong> Exploration bonuses for discovering new signals</p></li>
<li><p><strong>Meta-Learning:</strong> Reward functions that adapt to new scenarios</p></li>
</ol>
<p>This deep dive explains not just what we chose, but why we chose it, what alternatives we considered, and how we validated our decisions through systematic analysis.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, GeminiSDR Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>